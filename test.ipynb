{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf')\n",
    "\n",
    "import os\n",
    "from PIL import Image, ImageFilter, ImageOps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import skimage.transform\n",
    "import cv2\n",
    "from pykuwahara import kuwahara\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\".\",\"plain\")\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "val_dir = os.path.join(data_dir, \"val\")\n",
    "train_fns = os.listdir(train_dir)\n",
    "val_fns = os.listdir(val_dir)\n",
    "\n",
    "def extract_integers(s):\n",
    "    return [int(num) for num in re.findall(r'\\d+', s)]\n",
    "\n",
    "def check_index(search_lst):\n",
    "    intlst = []\n",
    "    for i in search_lst:\n",
    "        if i != \".DS_Store\":\n",
    "            intlst.append(extract_integers(i)[0])\n",
    "    unique_lst = list(set(intlst))\n",
    "    unique_lst.sort()\n",
    "    return unique_lst\n",
    "\n",
    "def image_open(dir, num, backbone):\n",
    "    img = Image.open(dir + \"/\" + str(num) + backbone).convert(\"RGB\")\n",
    "    # img = img.resize((1200, 1200))\n",
    "    bbox = img.getbbox()\n",
    "    img = img.crop(bbox)\n",
    "    return img\n",
    "\n",
    "backbone_raw = \"_raw.jpeg\"\n",
    "backbone_rawindex = \"_raw.npy\"\n",
    "backbone_cleft = \"_cleft.jpeg\"\n",
    "backbone_cleftindex = \"_cleft.npy\"\n",
    "backbone_neuron = \"_neuron.jpeg\"\n",
    "backbone_neuronindex = \"_neuron.npy\"\n",
    "\n",
    "train_int = check_index(train_fns)\n",
    "# print(train_int)\n",
    "val_int = check_index(val_fns)\n",
    "\n",
    "indd = 100\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 5))\n",
    "raw_testimg = image_open(train_dir, train_int[indd], backbone_raw)\n",
    "raw_index = np.load(train_dir + \"/\" + str(train_int[indd]) + backbone_rawindex) # neuron index read from file\n",
    "neuron_testimg = image_open(train_dir, train_int[indd], backbone_cleft)\n",
    "neuron_index = np.load(train_dir + \"/\" + str(train_int[indd]) + backbone_cleftindex) # neuron index read from file\n",
    "cleft_testimg = image_open(train_dir, train_int[indd], backbone_cleft)\n",
    "\n",
    "\n",
    "def ndarray_to_image(array):\n",
    "    \"\"\"\n",
    "    Convert a NumPy array to a PIL Image object.\n",
    "\n",
    "    Parameters:\n",
    "    - array: A NumPy array to be converted.\n",
    "\n",
    "    Returns:\n",
    "    - A PIL Image object.\n",
    "    \"\"\"\n",
    "    # Ensure the array is of type uint8\n",
    "    if array.dtype != np.uint8:\n",
    "        # Normalize and convert the data to uint8\n",
    "        array = ((array - array.min()) / (array.max() - array.min()) * 255).astype(np.uint8)\n",
    "    return Image.fromarray(array)\n",
    "\n",
    "neuron_index = skimage.transform.resize(neuron_index, (944,944))\n",
    "neuron_index = ndarray_to_image(neuron_index)\n",
    "\n",
    "axes[0].imshow(raw_testimg)\n",
    "axes[1].imshow(neuron_testimg)\n",
    "axes[2].imshow(neuron_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = 10000\n",
    "color_array = np.random.choice(range(256), 3*num_items).reshape(-1, 3)\n",
    "print(color_array.shape)\n",
    "print(color_array[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 50\n",
    "acc = 100\n",
    "initial_centroids = [i/100 for i in range(100)]\n",
    "\n",
    "label_model = KMeans(n_clusters=num_classes)\n",
    "# label_model = KMeans(n_clusters=len(initial_centroids), init=initial_centroids, n_init=1)\n",
    "\n",
    "label_model.fit(color_array)\n",
    "print(label_model.cluster_centers_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model.predict(color_array[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_class = label_model.predict(np.array(neuron_testimg).reshape(-1, 3)).reshape(944, 944)\n",
    "\n",
    "raw_index = skimage.transform.resize(raw_index, (256,256))\n",
    "# neuron_index = skimage.transform.resize(neuron_index, (256,256))\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "im1 = axes[0].imshow(raw_testimg.resize((256,256)))\n",
    "im2 = axes[1].imshow(neuron_testimg.resize((256,256)))\n",
    "im3 = axes[2].imshow(label_class)\n",
    "im4 = axes[3].imshow(cleft_testimg.resize((256,256)))\n",
    "# cbar = plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "\n",
    "# for ax in axes:\n",
    "#     ax.axis('off')\n",
    "\n",
    "# print(f\"neuron_testimg: {np.array(neuron_testimg)}\")\n",
    "unique_elements, counts = np.unique(label_class, return_counts=True)\n",
    "# print((unique_elements, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe(img):\n",
    "    img_np = np.array(img)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    if len(img_np.shape) == 2:  # Grayscale image\n",
    "        img_clahe = clahe.apply(img_np)\n",
    "    else:  # Color image\n",
    "        img_clahe = np.dstack([clahe.apply(i) for i in cv2.split(img_np)])\n",
    "    return Image.fromarray(img_clahe)\n",
    "\n",
    "# Define a custom transform for Canny edge detection\n",
    "def apply_canny(img):\n",
    "    img_np = np.array(img.convert('L'))  # Convert to grayscale\n",
    "    edges = cv2.Canny(img_np, 100, 200)\n",
    "    return Image.fromarray(edges).convert('RGB')  # Convert back to RGB\n",
    "\n",
    "def most_common(lst):\n",
    "    try: \n",
    "        val = max(set(lst), key=lst.count)\n",
    "    except ValueError:\n",
    "        val = 1e10\n",
    "    return val\n",
    "\n",
    "def apply_smooth(img):\n",
    "    half_width = 1\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            target = img[i][j]\n",
    "            backlst = []\n",
    "            for ii in range(max(0, i-half_width), min(img.shape[0], i+half_width+1)):\n",
    "                for jj in range(max(1, j-half_width), min(img.shape[1], j+half_width+1)):\n",
    "                    backlst.append(img[ii][jj])\n",
    "            # print(backlst)\n",
    "            new_target = most_common(backlst)\n",
    "            img[i][j] = new_target\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuronDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_model):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_fns = os.listdir(image_dir)\n",
    "        self.index_lst = check_index(self.image_fns)\n",
    "        self.label_model = label_model\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_fns) // 6\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # assert index in self.index_lst\n",
    "        raw_testimg = image_open(train_dir, index, backbone_raw)\n",
    "        raw_index = np.load(train_dir + \"/\" + str(train_int[0]) + backbone_rawindex) # neuron index read from file\n",
    "        neuron_testimg = image_open(train_dir, index, backbone_cleft).resize((256,256))\n",
    "        label_class = label_model.predict(np.array(neuron_testimg).reshape(-1, 3)).reshape(256, 256)\n",
    "        neuron_index = np.load(train_dir + \"/\" + str(index) + backbone_cleftindex)\n",
    "         \n",
    "        raw_index = skimage.transform.resize(raw_index, (256,256))\n",
    "        neuron_index = skimage.transform.resize(neuron_index, (256,256)) \n",
    "        raw_testimg = raw_testimg.resize((256,256))\n",
    "        # label_class = skimage.transform.resize(label_class, (256,256))\n",
    "\n",
    "        test = 0\n",
    "    \n",
    "        # preprocess\n",
    "        raw_testimg = np.array(raw_testimg)\n",
    "        raw_testimg = self.transform(raw_testimg)\n",
    "\n",
    "        if test == 1:\n",
    "            raw_testimg = np.array(raw_testimg).transpose(1,2,0)\n",
    "            plt.figure()\n",
    "            print(np.array(raw_testimg).shape)\n",
    "            plt.imshow(raw_testimg)\n",
    "        \n",
    "        raw_index = torch.Tensor(raw_index).long() \n",
    "        minval = np.min(neuron_index)\n",
    "        neuron_index = torch.Tensor(neuron_index / minval).long()\n",
    "\n",
    "        if test == 1: \n",
    "            print(label_class)\n",
    "            print(f\"type label_class: {type(label_class)}\")\n",
    "        \n",
    "        label_class = apply_smooth(label_class)\n",
    "        label_class = torch.Tensor(label_class).long()\n",
    "\n",
    "        if test == 1: \n",
    "            # print(label_class.numpy())\n",
    "            plt.figure()\n",
    "            plt.imshow(label_class)\n",
    "         \n",
    "        return raw_testimg, label_class\n",
    "    \n",
    "    def transform(self, image):\n",
    "        transform_ops = transforms.Compose([\n",
    "            # transforms.Lambda(lambda img: apply_clahe(img)),\n",
    "            # transforms.Lambda(lambda img: apply_canny(img)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "        return transform_ops(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_regions(size, num_regions=5, min_region_size=10, max_region_size=50):\n",
    "    regions = []\n",
    "\n",
    "    for _ in range(num_regions):\n",
    "        width, height = size\n",
    "\n",
    "        # Randomly determine the size of the region\n",
    "        region_width = random.randint(min_region_size, max_region_size)\n",
    "        region_height = random.randint(min_region_size, max_region_size)\n",
    "\n",
    "        # Randomly determine the starting point of the region\n",
    "        x_start = random.randint(0, width - region_width)\n",
    "        y_start = random.randint(0, height - region_height)\n",
    "\n",
    "        # Calculate the end points of the region\n",
    "        x_end = x_start + region_width\n",
    "        y_end = y_start + region_height\n",
    "\n",
    "        regions.append((x_start, x_end, y_start, y_end))\n",
    "\n",
    "    return regions\n",
    "\n",
    "def perturb_segmentation_aggressively(label_graph, perturbation_radius=3, high_perturb_probability=0.9, low_perturb_probability=0.5, num_high_perturb_regions=10, min_region_size=20, max_region_size=80):\n",
    "    # Generate random high perturbation regions\n",
    "    rows, cols = label_graph.shape\n",
    "    high_perturb_regions = generate_random_regions((rows, cols), num_high_perturb_regions, min_region_size, max_region_size)\n",
    "\n",
    "    # Helper function to check if a point is in a high perturbation region\n",
    "    def in_high_perturb_region(x, y, regions):\n",
    "        for region in regions:\n",
    "            if region[0] <= x < region[1] and region[2] <= y < region[3]:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Create a copy of the graph to perturb\n",
    "    perturbed_graph = np.array(label_graph)\n",
    "\n",
    "    # Iterate over each point in the graph\n",
    "    for x in range(rows):\n",
    "        for y in range(cols):\n",
    "            # Determine the probability of perturbation for this point\n",
    "            if in_high_perturb_region(x, y, high_perturb_regions):\n",
    "                perturb_probability = high_perturb_probability\n",
    "            else:\n",
    "                perturb_probability = low_perturb_probability\n",
    "\n",
    "            # Randomly decide whether to perturb this point\n",
    "            if random.random() < perturb_probability:\n",
    "                # Define the neighborhood boundary\n",
    "                x_min = max(x - perturbation_radius, 0)\n",
    "                x_max = min(x + perturbation_radius + 1, rows)\n",
    "                y_min = max(y - perturbation_radius, 0)\n",
    "                y_max = min(y + perturbation_radius + 1, cols)\n",
    "\n",
    "                # Extract the neighborhood\n",
    "                neighborhood = label_graph[x_min:x_max, y_min:y_max]\n",
    "\n",
    "                # Choose a random point from the neighborhood\n",
    "                random_point = neighborhood[np.random.randint(0, neighborhood.shape[0]), \n",
    "                                            np.random.randint(0, neighborhood.shape[1])]\n",
    "\n",
    "                # Update the label of the current point\n",
    "                perturbed_graph[x, y] = random_point\n",
    "\n",
    "    return perturbed_graph\n",
    "\n",
    "\n",
    "def extract_label_boundaries(label_array):\n",
    "    boundaries = {}\n",
    "    unique_labels = np.unique(label_array)\n",
    "\n",
    "    for label in unique_labels:\n",
    "        # Create a mask for the current label\n",
    "        mask = np.where(label_array == label, 255, 0).astype(np.uint8)\n",
    "        # Find contours (boundaries) of the label\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Store the contours in the dictionary\n",
    "        boundaries[label] = contours\n",
    "        # print(contours)\n",
    "\n",
    "    return boundaries\n",
    "\n",
    "def remove_element(lst, element_to_remove):\n",
    "    return [element for element in lst if element != element_to_remove]\n",
    "\n",
    "\n",
    "def perturb_labels_smooth(labels, kernel_size=5, erosion_iter=3, dilation_iter=3):\n",
    "    # Create circular (elliptical) kernels for erosion and dilation\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    \n",
    "    # Apply erosion to reduce the label size with a smoother effect\n",
    "    eroded_labels = cv2.erode(labels.astype(np.uint8), kernel, iterations=erosion_iter)\n",
    "    \n",
    "    # Apply dilation to restore the label size with a smoother effect\n",
    "    dilated_labels = cv2.dilate(eroded_labels, kernel, iterations=dilation_iter)\n",
    "    \n",
    "    return dilated_labels\n",
    "\n",
    "def iter_boundary(img, boundary, prob=1, radius=5, ind=10):\n",
    "    keys = list(boundary.keys())\n",
    "    for i in keys:\n",
    "        thebound = boundary[i][0]\n",
    "        for pt_ind in thebound:\n",
    "            rand = random.uniform(0,1)\n",
    "            if rand < prob:\n",
    "                pt_ind = pt_ind[0]\n",
    "                ptx, pty = pt_ind[0], pt_ind[1]\n",
    "                for ptxx in range(max(0, ptx-random.randint(1,ind)),min(img.shape[0], ptx+random.randint(1,ind))):\n",
    "                    for ptyy in range(max(0, pty-random.randint(1,ind)), min(img.shape[1], pty+random.randint(1,ind))):\n",
    "                        lst = []\n",
    "                        for i in range(max(0, ptxx-radius), min(img.shape[0], ptxx+radius)):\n",
    "                            for j in range(max(0, ptyy-radius), min(img.shape[1], ptyy+radius)):\n",
    "                                lst.append(img[i][j])\n",
    "                        lv = img[ptxx][ptyy]\n",
    "                        # print(lv)\n",
    "                        lst = remove_element(lst, lv)\n",
    "                        # print(lst)\n",
    "                        ll = most_common(lst)\n",
    "                        # print(f\"diff: {ll-lv}\")\n",
    "                        if ll == 1e10:\n",
    "                            img[ptxx][ptyy] = lv\n",
    "                        else:\n",
    "                            img[ptxx][ptyy] = ll\n",
    "                \n",
    "                \n",
    "    return img\n",
    "\n",
    "def find_sig(img, cut=0.5):\n",
    "    indexlst = []\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if img[i][j] > cut:\n",
    "                indexlst.append((i,j))\n",
    "    print(indexlst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NeuronDataset(train_dir, label_model)\n",
    "print(len(dataset))\n",
    "raw_image, label_class = dataset[10]\n",
    "print(raw_image.shape, label_class.shape)\n",
    "\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(label_class[4:-4, 4:-4])\n",
    "# plt.colorbar()\n",
    "\n",
    "# # single test\n",
    "# label_class = np.array(label_class)\n",
    "# boundary = extract_label_boundaries(label_class)\n",
    "# new_label = iter_boundary(label_class, boundary, 0.5)\n",
    "\n",
    "# new_label = label_class[4:-4, 4:-4]\n",
    "\n",
    "# # plt.figure()\n",
    "# # plt.imshow(new_label)\n",
    "\n",
    "# put_label = perturb_labels_smooth(new_label, kernel_size=10, erosion_iter=5, dilation_iter=10)\n",
    "# # put_label = find_sig(new_label)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.imshow(new_label)\n",
    "# plt.colorbar()\n",
    "\n",
    "# print(new_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.contracting_11 = self.conv_block(in_channels=3, out_channels=64)\n",
    "        self.contracting_12 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_21 = self.conv_block(in_channels=64, out_channels=128)\n",
    "        self.contracting_22 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_31 = self.conv_block(in_channels=128, out_channels=256)\n",
    "        self.contracting_32 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_41 = self.conv_block(in_channels=256, out_channels=512)\n",
    "        self.contracting_42 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.middle = self.conv_block(in_channels=512, out_channels=1024)\n",
    "        self.expansive_11 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.expansive_12 = self.conv_block(in_channels=1024, out_channels=512)\n",
    "        self.expansive_21 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.expansive_22 = self.conv_block(in_channels=512, out_channels=256)\n",
    "        self.expansive_31 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.expansive_32 = self.conv_block(in_channels=256, out_channels=128)\n",
    "        self.expansive_41 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.expansive_42 = self.conv_block(in_channels=128, out_channels=64)\n",
    "        self.output = nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(num_features=out_channels),\n",
    "                                    nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.BatchNorm2d(num_features=out_channels))\n",
    "        return block\n",
    "    \n",
    "    def forward(self, X):\n",
    "        contracting_11_out = self.contracting_11(X) # [-1, 64, 256, 256]\n",
    "        contracting_12_out = self.contracting_12(contracting_11_out) # [-1, 64, 128, 128]\n",
    "        contracting_21_out = self.contracting_21(contracting_12_out) # [-1, 128, 128, 128]\n",
    "        contracting_22_out = self.contracting_22(contracting_21_out) # [-1, 128, 64, 64]\n",
    "        contracting_31_out = self.contracting_31(contracting_22_out) # [-1, 256, 64, 64]\n",
    "        contracting_32_out = self.contracting_32(contracting_31_out) # [-1, 256, 32, 32]\n",
    "        contracting_41_out = self.contracting_41(contracting_32_out) # [-1, 512, 32, 32]\n",
    "        contracting_42_out = self.contracting_42(contracting_41_out) # [-1, 512, 16, 16]\n",
    "        middle_out = self.middle(contracting_42_out) # [-1, 1024, 16, 16]\n",
    "        expansive_11_out = self.expansive_11(middle_out) # [-1, 512, 32, 32]\n",
    "        expansive_12_out = self.expansive_12(torch.cat((expansive_11_out, contracting_41_out), dim=1)) # [-1, 1024, 32, 32] -> [-1, 512, 32, 32]\n",
    "        expansive_21_out = self.expansive_21(expansive_12_out) # [-1, 256, 64, 64]\n",
    "        expansive_22_out = self.expansive_22(torch.cat((expansive_21_out, contracting_31_out), dim=1)) # [-1, 512, 64, 64] -> [-1, 256, 64, 64]\n",
    "        expansive_31_out = self.expansive_31(expansive_22_out) # [-1, 128, 128, 128]\n",
    "        expansive_32_out = self.expansive_32(torch.cat((expansive_31_out, contracting_21_out), dim=1)) # [-1, 256, 128, 128] -> [-1, 128, 128, 128]\n",
    "        expansive_41_out = self.expansive_41(expansive_32_out) # [-1, 64, 256, 256]\n",
    "        expansive_42_out = self.expansive_42(torch.cat((expansive_41_out, contracting_11_out), dim=1)) # [-1, 128, 256, 256] -> [-1, 64, 256, 256]\n",
    "        output_out = self.output(expansive_42_out) # [-1, num_classes, 256, 256]\n",
    "        return output_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchviz import make_dot\n",
    "# import hiddenlayer as hl\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# x = torch.randn(1, 3, 256, 256)  # Example input tensor matching the input size of your network\n",
    "# y = model(x)\n",
    "# dot = make_dot(y, params=dict(list(model.named_parameters()) + [('x', x)]))\n",
    "# dot.render('unet_graph', format='png')  # This will save the graph as 'unet_graph.png'\n",
    "\n",
    "# writer = SummaryWriter()\n",
    "# images = vutils.make_grid(images, normalize=True, scale_each=True)\n",
    "# dummy_input = torch.randn(1, 3, 256, 256)\n",
    "# writer.add_graph(model, dummy_input)\n",
    "# writer.add_image('Image', images, 0)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=4)\n",
    "print(len(dataset), len(data_loader))\n",
    "\n",
    "X, Y = next(iter(data_loader))\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "Y_pred = model(X)\n",
    "print(Y_pred.shape)\n",
    "\n",
    "Y_pred = torch.argmax(Y_pred, dim=1)\n",
    "plt.imshow(Y_pred[2].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "epochs = 15\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = F.softmax(inputs, dim=1)  # Apply softmax to the inputs\n",
    "        \n",
    "        # Flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice\n",
    "    \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits:\n",
    "            BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss\n",
    "        \n",
    "class IoULoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IoULoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = F.softmax(inputs, dim=1)  # Apply softmax to the inputs\n",
    "\n",
    "        # Flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()\n",
    "        total = (inputs + targets).sum()\n",
    "        union = total - intersection \n",
    "        \n",
    "        IoU = (intersection + smooth)/(union + smooth)\n",
    "                \n",
    "        return 1 - IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NeuronDataset(train_dir, label_model)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size)\n",
    "model = UNet(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = DiceLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "step_losses = []\n",
    "epoch_losses = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    epoch_loss = 0\n",
    "    for X, Y in tqdm(data_loader, total=len(data_loader), leave=False):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X)\n",
    "        loss = criterion(Y_pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        step_losses.append(loss.item())\n",
    "    epoch_losses.append(epoch_loss/len(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(step_losses)\n",
    "plt.title(\"Step Losses\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Losses\")\n",
    "# axes[0].set_yscale('log')\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(epoch_losses)\n",
    "plt.title(\"Epoch Losses\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Losses\")\n",
    "# axes[1].set_yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"U-Net.pth\"\n",
    "torch.save(model.state_dict(), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"U-Net.pth\"\n",
    "model_ = UNet(num_classes=num_classes).to(device)\n",
    "model_.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_size = 2\n",
    "dataset = NeuronDataset(train_dir, label_model)\n",
    "data_loader = DataLoader(dataset, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = next(iter(data_loader))\n",
    "X, Y = X.to(device), Y.to(device)\n",
    "print(X.shape, Y.shape)\n",
    "Y_pred = model_(X)\n",
    "print(Y_pred.shape)\n",
    "Y_pred = torch.argmin(Y_pred, dim=1)\n",
    "print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_transform = transforms.Compose([\n",
    "    transforms.Normalize((-0.485/0.229, -0.456/0.224, -0.406/0.225), (1/0.229, 1/0.224, 1/0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(test_batch_size, 2, figsize=(3*5, test_batch_size*5))\n",
    "\n",
    "for i in range(test_batch_size):\n",
    "    \n",
    "    landscape = inverse_transform(X[i]).permute(1, 2, 0).cpu().detach().numpy()\n",
    "    label_class = Y[i].cpu().detach().numpy()\n",
    "    label_class_predicted = Y_pred[i].cpu().detach().numpy()\n",
    "\n",
    "    # perturb_label = perturb_segmentation_aggressively(label_class)\n",
    "    \n",
    "    # axes[i, 0].imshow(landscape)\n",
    "    # axes[i, 0].set_title(\"Landscape\")\n",
    "    axes[i, 0].imshow(label_class)\n",
    "    axes[i, 0].set_title(\"Label Class\")\n",
    "    axes[i, 1].imshow(perturb_labels_smooth(label_class,kernel_size=7))\n",
    "    axes[i, 1].set_title(\"Label Class - Predicted\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uwzihan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
